# -*- coding: utf-8 -*-
"""Car Evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19GxkBmCTl4ie5bvBR7YolsbaivKcMZPu
"""

pip install category_encoders

import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from category_encoders import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

dataset=pd.read_csv('cars.csv')
x=dataset.iloc[:,1:-1]
y=dataset.iloc[:,-1]

x.iloc[:,0:2].replace({'vhigh':3,'high':2,'med':1,'low':0},inplace=True) 
x.iloc[:,-2].replace({'small':0,'med':1,'big':2},inplace=True)
x.iloc[:,-1].replace({'low':0,'med':1,'high':2},inplace=True)
#ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[2])],remainder='passthrough')
oe=OneHotEncoder(cols=['persons','doors'])
x=oe.fit_transform(x)
x=x.drop(['persons_1','doors_1'],axis='columns')

"""Splitting data into training and test dataset"""

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)
xtrain

"""Feature scaling"""

sc=StandardScaler()
xtrain.iloc[:,:2]=sc.fit_transform(xtrain.iloc[:,:2])
xtest.iloc[:,:2]=sc.fit_transform(xtest.iloc[:,:2])
xtrain.iloc[:,-2:]=sc.fit_transform(xtrain.iloc[:,-2:])
xtest.iloc[:,-2:]=sc.fit_transform(xtest.iloc[:,-2:])
xtrain

"""Training the calssification models on training set

1) Knn
"""

#print("select the model to use or check the scores of each \n 1) knn\n 2) Random Forest\n 3) Naive bayes\n 4) Decision tree\n 5) Logistic regression/n 6) SVC(Support vector classificaion)")
knn=KNeighborsClassifier(n_neighbors=5,metric='minkowski')
knn.fit(xtrain,ytrain)
ypred_knn=knn.predict(xtest)
cs=classification_report(ytest,ypred_knn)
print(cs)

"""2) Random forest"""

rf=RandomForestClassifier(n_estimators=100,criterion='entropy')
rf.fit(xtrain,ytrain)
ypred_rf=rf.predict(xtest)
cs=classification_report(ytest,ypred_rf)
print(cs)

"""3) Naive Bayes"""

nb=GaussianNB()
nb.fit(xtrain,ytrain)
ypred_nb=nb.predict(xtest)
cs=classification_report(ytest,ypred_nb)
print(cs)

"""4) Decision tree"""

dt=DecisionTreeClassifier(criterion='entropy')
dt.fit(xtrain,ytrain)
ypred_dt=dt.predict(xtest)
cs=classification_report(ytest,ypred_dt)
print(cs)

"""5) Logistic regression"""

lr=LogisticRegression()
lr.fit(xtrain,ytrain)
ypred_lr=lr.predict(xtest)
cs=classification_report(ytest,ypred_lr)
print(cs)

"""6) Support vector classification"""

sv=SVC(C=1.0,kernel='rbf',degree=3)
sv.fit(xtrain,ytrain)
ypred_sv=sv.predict(xtest)
cs=classification_report(ytest,ypred_sv)
print(cs)